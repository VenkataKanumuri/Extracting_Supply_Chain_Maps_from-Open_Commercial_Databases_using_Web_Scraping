{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "341e9e56",
   "metadata": {},
   "source": [
    "Fetching News Articles: Company name(Dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b13f2503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the company name: Apple\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from config import API_KEY\n",
    "\n",
    "def fetch_company_news(company_name):\n",
    "    base_url = 'https://newsapi.org/v2'\n",
    "    endpoint = '/everything'\n",
    "\n",
    "    search_query = '{} suppliers'.format(company_name)\n",
    "\n",
    "    # Query parameters\n",
    "    query_params = {\n",
    "        'q': search_query,\n",
    "        'apiKey': API_KEY,\n",
    "        'sortBy': 'publishedAt',\n",
    "        'language': 'en',\n",
    "        'pageSize': 20,  # Number of articles\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url + endpoint, params=query_params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data['articles']\n",
    "        \n",
    "        seen_titles = set()  # To keep track of titles already written\n",
    "\n",
    "        output_filename = '{}_news_articles.txt'.format(company_name.replace(\" \", \"_\"))\n",
    "        with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "            for article in articles:\n",
    "                title = article['title']\n",
    "\n",
    "                # Check if article with this title is already written\n",
    "                if title in seen_titles:\n",
    "                    continue\n",
    "                \n",
    "                # If not, add the title to the set\n",
    "                seen_titles.add(title)\n",
    "\n",
    "                content = article.get('content', 'No content available')\n",
    "                published_at = article['publishedAt']\n",
    "                url = article['url']\n",
    "\n",
    "                file.write('Title: {}\\n'.format(title))\n",
    "                file.write('Content: {}\\n'.format(content))\n",
    "                file.write('Published Date: {}\\n'.format(published_at))\n",
    "                file.write('URL: {}\\n'.format(url))\n",
    "                file.write('-' * 30 + '\\n')  # Separator between news articles\n",
    "    else:\n",
    "        print('Error:', response.status_code)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    company = input(\"Enter the company name: \")\n",
    "    fetch_company_news(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02f7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "327fb42b",
   "metadata": {},
   "source": [
    "Limitation for above code is that the content coloumn can only display 200chars (Due to NewsAPI free account restriction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769048cc",
   "metadata": {},
   "source": [
    "Using BeautifulSoup we go to the url and Scrape the article from the Source website (Including time frame)\n",
    "{Not applicable for free account in NewsAPI - Only restricted to Search articles up to a month old }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dde6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from config import API_KEY\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_full_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        return '\\n'.join([p.get_text() for p in paragraphs])\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching full content: {e}\"\n",
    "\n",
    "def is_phrase_in_sentence(phrase, company, content):\n",
    "    sentences = content.split('.')\n",
    "    for sentence in sentences:\n",
    "        if phrase in sentence and company in sentence:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def fetch_company_suppliers_news(company_name, from_date, to_date):\n",
    "    base_url = 'https://newsapi.org/v2'\n",
    "    endpoint = '/everything'\n",
    "\n",
    "    search_query = '(\"supplies to\" OR \"partner with\") {}'.format(company_name)\n",
    "\n",
    "    query_params = {\n",
    "        'q': search_query,\n",
    "        'from': from_date,\n",
    "        'to': to_date,\n",
    "        'apiKey': API_KEY,\n",
    "        'sortBy': 'publishedAt',\n",
    "        'language': 'en',\n",
    "        'pageSize': 20,  # Ideally more results as we will filter them further\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url + endpoint, params=query_params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data['articles']\n",
    "\n",
    "        output_filename = '{}_supplier_articles_{}_to_{}.txt'.format(company_name.replace(\" \", \"_\"), from_date, to_date)\n",
    "        with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "            for article in articles:\n",
    "                title = article['title']\n",
    "                url = article['url']\n",
    "                published_date = article['publishedAt']\n",
    "\n",
    "                full_content = fetch_full_content(url)\n",
    "\n",
    "                if not (is_phrase_in_sentence(\"supplies to\", company_name, full_content) or \n",
    "                        is_phrase_in_sentence(\"partner with\", company_name, full_content)):\n",
    "                    continue\n",
    "\n",
    "                file.write('Title: {}\\n'.format(title))\n",
    "                file.write('Published Date: {}\\n'.format(published_date))\n",
    "                file.write('Full Content: {}\\n'.format(full_content))\n",
    "                file.write('URL: {}\\n'.format(url))\n",
    "                file.write('-' * 50 + '\\n')  # Separator\n",
    "    else:\n",
    "        print('Error:', response.status_code)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    company = input(\"Enter the company name: \")\n",
    "\n",
    "    # Get the date range from the user\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    while True:\n",
    "        from_date = input(\"Enter the start date (YYYY-MM-DD): \")\n",
    "        to_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "        try:\n",
    "            # Validate date format\n",
    "            datetime.strptime(from_date, date_format)\n",
    "            datetime.strptime(to_date, date_format)\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid date format. Please use YYYY-MM-DD.\")\n",
    "\n",
    "    fetch_company_suppliers_news(company, from_date, to_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1addac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
